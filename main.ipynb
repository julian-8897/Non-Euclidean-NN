{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e00c480ae7e3d5e7171f38ea6fedffbe731b8808f4aa360dec46acf6f1daf018"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import feed_forward\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision\r\n",
    "import geoopt\r\n",
    "from time import time\r\n",
    "from torchvision import datasets, transforms\r\n",
    "import helper\r\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "CUDA check"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "device"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Transformation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\r\n",
    "                                \r\n",
    "                              ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training and Test data from MNIST data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\r\n",
    "n_inputs = 784\r\n",
    "valset = datasets.MNIST('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\r\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True)\r\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=512, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initializing the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "model = feed_forward.HypFF()\r\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HypFF(\n",
       "  (fc1): MobLinear(\n",
       "    in_features=784, out_features=512, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       "  (fc2): MobLinear(\n",
       "    in_features=512, out_features=256, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       "  (fc3): MobLinear(\n",
       "    in_features=256, out_features=10, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "HypFF(\n",
      "  (fc1): MobLinear(\n",
      "    in_features=784, out_features=512, bias=True\n",
      "    (ball): PoincareBall manifold\n",
      "  )\n",
      "  (fc2): MobLinear(\n",
      "    in_features=512, out_features=256, bias=True\n",
      "    (ball): PoincareBall manifold\n",
      "  )\n",
      "  (fc3): MobLinear(\n",
      "    in_features=256, out_features=10, bias=True\n",
      "    (ball): PoincareBall manifold\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "#learning_rate = 64e-1 #learning rate for logSigmoid activation function\r\n",
    "learning_rate = 2e-1 #learning rate for ReLU activation function\r\n",
    "#learning_rate = 2e-1 #current learning rate for model without activation functions\r\n",
    "momentum = 0.9"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loss Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "criterion = nn.CrossEntropyLoss()\r\n",
    "#criterion = nn.NLLLoss()\r\n",
    "images, labels = next(iter(trainloader))\r\n",
    "images, labels = images.to(device), labels.to(device)\r\n",
    "images = 0.0357*images.view(images.shape[0], -1)\r\n",
    "print(images)\r\n",
    "\r\n",
    "out = model(images) #output\r\n",
    "print(out)\r\n",
    "loss = criterion(out, labels) #calculate the loss"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[ 0.1243,  0.0717,  0.0693,  ..., -0.2646,  0.0656,  0.1606],\n",
      "        [ 0.1242,  0.0717,  0.0693,  ..., -0.2646,  0.0656,  0.1606],\n",
      "        [ 0.1242,  0.0717,  0.0693,  ..., -0.2646,  0.0657,  0.1606],\n",
      "        ...,\n",
      "        [ 0.1242,  0.0718,  0.0693,  ..., -0.2646,  0.0657,  0.1605],\n",
      "        [ 0.1243,  0.0717,  0.0693,  ..., -0.2646,  0.0656,  0.1606],\n",
      "        [ 0.1243,  0.0717,  0.0694,  ..., -0.2646,  0.0656,  0.1606]],\n",
      "       device='cuda:0', grad_fn=<SWhereBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "optimizer = geoopt.optim.RiemannianSGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "\r\n",
    "time0 = time()\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for e in range(epochs):\r\n",
    "    running_loss = 0\r\n",
    "    for images, labels in trainloader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        # Flatten MNIST images into a 784 long vector\r\n",
    "        images = 0.0357*images.view(images.shape[0], -1)\r\n",
    "    \r\n",
    "        # Training pass\r\n",
    "        optimizer.zero_grad()\r\n",
    "        \r\n",
    "        output = model(images)\r\n",
    "        loss = criterion(output, labels)\r\n",
    "        \r\n",
    "        #backpropagation\r\n",
    "        loss.backward()\r\n",
    "        \r\n",
    "        #Weight optimization\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        running_loss += loss.item()\r\n",
    "    else:\r\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\r\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0 - Training loss: 2.3052541744911066\n",
      "Epoch 1 - Training loss: 2.3017156629239097\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images, labels = next(iter(valloader))\r\n",
    "#images, labels = images.to(device), labels.to(device)\r\n",
    "\r\n",
    "img = 0.0357*images[0].view(1, 784)\r\n",
    "img_gpu = img.to(device)\r\n",
    "with torch.no_grad():\r\n",
    "    out = model(img_gpu)\r\n",
    "\r\n",
    "ps = out.cpu()\r\n",
    "print(ps)\r\n",
    "probab = list(ps.numpy()[0])\r\n",
    "print(probab)\r\n",
    "print(\"Predicted Digit =\", probab.index(max(probab)))\r\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.3237, -0.1945, -0.3137, -0.2813, -0.3414, -0.4027, -0.3311, -0.2654,\n",
      "         -0.3368, -0.3157]])\n",
      "[-0.323748, -0.19453931, -0.31367132, -0.2812643, -0.34142232, -0.40268695, -0.33109415, -0.26538754, -0.336813, -0.3156511]\n",
      "Predicted Digit = 1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "correct_count, all_count = 0, 0\r\n",
    "for images,labels in valloader:\r\n",
    "  images, labels = images.to(device), labels.to(device)\r\n",
    "  for i in range(len(labels)):\r\n",
    "    img = 0.0357*images[i].view(1, 784)\r\n",
    "    with torch.no_grad():\r\n",
    "        out = model(img)\r\n",
    "\r\n",
    "    \r\n",
    "    ps = out.cpu()\r\n",
    "    probab = list(ps.numpy()[0])\r\n",
    "    pred_label = probab.index(max(probab))\r\n",
    "    true_label = labels.cpu().numpy()[i]\r\n",
    "    if(true_label == pred_label):\r\n",
    "      correct_count += 1\r\n",
    "    all_count += 1\r\n",
    "\r\n",
    "print(\"Number Of Images Tested =\", all_count)\r\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.1135\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Current status of experiments:\r\n",
    "1. Using just Hyperboic Linear modules, and with the appropriate self-tuned hyperparameters, and a batch size of 512, the average accuracy converged around 90 percent\r\n",
    "2. With the use of activation functions(ReLu, ReLu, then LogSoftMax at the output layer), (by applying the functions in the tangent space, then mapping it nack to the hyperbolic space), we see an increase in the model accuracy to about 97.7 percent.\r\n",
    "3. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}