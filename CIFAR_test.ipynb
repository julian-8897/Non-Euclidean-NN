{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "Imports"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 323,
            "source": [
                "from models import ff_hyp, ff_eucl\r\n",
                "import numpy as np\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "import torch\r\n",
                "import torch.nn as nn\r\n",
                "import torch.optim as optim\r\n",
                "import torchvision\r\n",
                "import geoopt\r\n",
                "from time import time\r\n",
                "from torchvision import datasets, transforms\r\n",
                "torch.cuda.is_available()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "False"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 323
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "CUDA check"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 324,
            "source": [
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
                "device"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "device(type='cpu')"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 324
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 325,
            "source": [
                "transform = transforms.Compose([transforms.Grayscale(num_output_channels=3),\r\n",
                "                                transforms.ToTensor(), \r\n",
                "                                #transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\r\n",
                "                                ])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 326,
            "source": [
                "trainset = datasets.CIFAR10('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\r\n",
                "valset = datasets.CIFAR10('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 327,
            "source": [
                "label_map = {0: 0, 5: 1}\r\n",
                "class_names = ['airplane', 'dog']\r\n",
                "cifar2 = [(img, label_map[label]) for img, label in trainset if label in [0, 5]]\r\n",
                "cifar2_val = [(img, label_map[label]) for img, label in valset if label in [0, 5]]\r\n",
                "\r\n",
                "trainloader = torch.utils.data.DataLoader(cifar2, batch_size=512, shuffle=True)\r\n",
                "valloader = torch.utils.data.DataLoader(cifar2_val, batch_size=512, shuffle=False)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 328,
            "source": [
                "# img_ex, label_ex = cifar2[7]\r\n",
                "# plt.imshow(img_ex)\r\n",
                "# plt.show()\r\n",
                "\r\n",
                "# len(cifar2_val)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Initializing the model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 329,
            "source": [
                "model = ff_hyp.HypFF(3072, 512, 256, 2, nn.ReLU())\r\n",
                "ball = geoopt.PoincareBall()\r\n",
                "model"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "HypFF(\n",
                            "  (act_fn): ReLU()\n",
                            "  (fc1): MobLinear(\n",
                            "    in_features=3072, out_features=512, bias=True\n",
                            "    (ball): PoincareBall manifold\n",
                            "  )\n",
                            "  (fc2): MobLinear(\n",
                            "    in_features=512, out_features=256, bias=True\n",
                            "    (ball): PoincareBall manifold\n",
                            "  )\n",
                            "  (fc3): MobLinear(\n",
                            "    in_features=256, out_features=2, bias=True\n",
                            "    (ball): PoincareBall manifold\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 329
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 330,
            "source": [
                "learning_rate = 2e-3\r\n",
                "momentum = 0.5"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 331,
            "source": [
                "optimizer = geoopt.optim.RiemannianSGD(model.parameters(), \r\n",
                "                                       lr=learning_rate, momentum=momentum)\r\n",
                "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\r\n",
                "loss_fn = nn.CrossEntropyLoss()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 332,
            "source": [
                "n_epochs = 15\r\n",
                "for epoch in range(n_epochs):\r\n",
                "    for imgs, labels in trainloader:\r\n",
                "        # img, label = img.to(device), label.to(device)\r\n",
                "        batch_size = imgs.shape[0]\r\n",
                "        out = model(ball.projx(imgs.view(batch_size, -1)))\r\n",
                "        loss = loss_fn(out, labels)\r\n",
                "        optimizer.zero_grad()\r\n",
                "        loss.backward()\r\n",
                "        optimizer.step()\r\n",
                "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch: 0, Loss: 0.691606\n",
                        "Epoch: 1, Loss: 0.692921\n",
                        "Epoch: 2, Loss: 0.693511\n",
                        "Epoch: 3, Loss: 0.693508\n",
                        "Epoch: 4, Loss: 0.692924\n",
                        "Epoch: 5, Loss: 0.692464\n",
                        "Epoch: 6, Loss: 0.693612\n",
                        "Epoch: 7, Loss: 0.693834\n",
                        "Epoch: 8, Loss: 0.692364\n",
                        "Epoch: 9, Loss: 0.692256\n",
                        "Epoch: 10, Loss: 0.692817\n",
                        "Epoch: 11, Loss: 0.692929\n",
                        "Epoch: 12, Loss: 0.694026\n",
                        "Epoch: 13, Loss: 0.692061\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14184/1486064531.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch: %d, Loss: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "correct = 0\r\n",
                "total = 0\r\n",
                "\r\n",
                "with torch.no_grad():\r\n",
                "    for imgs, labels in valloader:\r\n",
                "        batch_size = imgs.shape[0]\r\n",
                "        outputs = model(ball.projx(imgs.view(batch_size, -1)))\r\n",
                "        _, predicted = torch.max(outputs, dim=1)\r\n",
                "        total += labels.shape[0]\r\n",
                "        correct += int((predicted == labels).sum())\r\n",
                "        \r\n",
                "print(\"Accuracy: %f\", correct / total)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Accuracy: %f 0.5\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit"
        },
        "interpreter": {
            "hash": "2454a3adb90052121e3433f22c2e288f84a7f03217a2a46086941be12932708b"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}