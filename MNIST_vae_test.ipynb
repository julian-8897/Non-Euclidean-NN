{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST experiment for VAE models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import vae_eucl_mnist, vae_hyp_mnist\n",
    "import numpy as np\n",
    "import geoopt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from hypmath import poincareball\n",
    "from hypmath import metrics\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#Disable Debugging APIs\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)\n",
    "\n",
    "#cuDNN Autotuner\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET',\n",
    "                               download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('PATH_TO_STORE_TESTSET',\n",
    "                            download=True, train=False, transform=transform)\n",
    "\n",
    "size = len(trainset)\n",
    "# print(size)\n",
    "\n",
    "#Splitting training set into training and validation data\n",
    "train_data, val_data = torch.utils.data.random_split(trainset, [int(size-size*0.2), int(size*0.2)])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=6, pin_memory=True)\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True, num_workers=6, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True, num_workers=6, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(vae, dataloader, optimizer):\n",
    "    \"\"\"\n",
    "    Model training function\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    vae.train()\n",
    "    train_loss = 0.0\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for x, _ in dataloader: \n",
    "        # Move tensor to the proper device\n",
    "        # x = x.to(device)\n",
    "        x_hat = vae(x)\n",
    "        # Evaluate loss\n",
    "        loss = ((x - x_hat)**2).sum() + (vae.encoder.kl)\n",
    "\n",
    "        # Backward pass\n",
    "        #optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        #print('\\t partial train loss (single batch): %f' % (loss.item()))\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    return train_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "def val_epoch(vae, dataloader):\n",
    "    \"\"\"\n",
    "    Model validation function\n",
    "    \"\"\"\n",
    "\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    vae.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        for x, _ in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            # x = x.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = vae.encoder(x)\n",
    "            # Decode data\n",
    "            x_hat = vae(x)\n",
    "            loss = ((x - x_hat)**2).sum() + vae.encoder.kl\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(dataloader.dataset)  \n",
    "\n",
    "\n",
    "def plot_ae_outputs(encoder,decoder,n):\n",
    "    \"\"\"\n",
    "    Plots the reconstructed images from VAE\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10,4.5))\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2,n,i+1)\n",
    "      img = testset[i][0].unsqueeze(0)\n",
    "      encoder.eval()\n",
    "      decoder.eval()\n",
    "      with torch.no_grad():\n",
    "         rec_img  = decoder(encoder(img))\n",
    "      plt.imshow(img.squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.show()   \n",
    "\n",
    "def model_eval(model, epochs, trainloader, valloader, optimizer):\n",
    "    \"\"\"\n",
    "    Function for model evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    tb = SummaryWriter()\n",
    "    t_loss = []\n",
    "    v_loss = []\n",
    "    epoch_values = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch(model, trainloader, optimizer) \n",
    "        t_loss.append(train_loss)\n",
    "        val_loss= val_epoch(model, valloader)\n",
    "        v_loss.append(val_loss)\n",
    "        epoch_values.append(epoch)\n",
    "\n",
    "        tb.add_scalar(\"Training Loss\", train_loss, epoch)\n",
    "        tb.add_scalar(\"Validation Loss\", val_loss, epoch)\n",
    "        print(\"epoch:\", epoch, \"training loss:\", train_loss, \"validation loss:\", val_loss)\n",
    "        plot_ae_outputs(model.encoder, model.decoder,n=6)\n",
    "        \n",
    "    return t_loss, v_loss, epoch_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = 4\n",
    "#model = vae_eucl_mnist.VariationalAutoencoder(latent_dims)\n",
    "model = vae_hyp_mnist.VariationalAutoencoder(latent_dims)\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "optimizer = geoopt.optim.RiemannianAdam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "t_loss, v_loss, epoch_values = model_eval(model, epochs, trainloader, valloader, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , (ax0) = plt.subplots(1, 1)\n",
    "ax0.set_title('Loss Curves')\n",
    "ax0.plot(epoch_values, t_loss, 'bo-', label='train')\n",
    "ax0.plot(epoch_values, v_loss, 'ro-', label='val')\n",
    "\n",
    "ax0.set_xlabel('Epochs')\n",
    "ax0.set_ylabel('Losses')\n",
    "ax0.legend()\n",
    "\n",
    "fig.suptitle('no. of epochs = {}, lr = {}, batch size = 64, latent dimensions = {}'.format(epochs, learning_rate, latent_dims))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Clustering of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_samples = []\n",
    "for sample in tqdm(testset):\n",
    "    img = sample[0].unsqueeze(0)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = model.encoder(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Latent Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "    \n",
    "encoded_samples = pd.DataFrame(encoded_samples)\n",
    "#print(encoded_samples)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "import plotly.express as px\n",
    "\n",
    "# #Davies-Bouldin Index\n",
    "# db_index = davies_bouldin_score(encoded_samples, encoded_samples.label)\n",
    "# print('Davies-Bouldin score :', db_index)\n",
    "\n",
    "# #Calinski-Harabasz Index\n",
    "# ch_score = calinski_harabasz_score(encoded_samples, encoded_samples.label)\n",
    "# print('Calinski-Harabasz score:', ch_score)\n",
    "\n",
    "#Silhouette Coefficient\n",
    "#s_coeff = silhouette_score(encoded_samples, encoded_samples.label,  metric=metrics.PoincareDistance)\n",
    "s_coeff = silhouette_score(encoded_samples, encoded_samples.label)\n",
    "print('Silhouette score :',s_coeff)\n",
    "\n",
    "px.scatter(encoded_samples, x='Latent Variable 0', y='Latent Variable 1', color=encoded_samples.label.astype(str), opacity=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE algorithm applied on the latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne = TSNE(n_components=2, metric=metrics.PoincareDistance)\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne_results = tsne.fit_transform(encoded_samples.drop(['label'],axis=1))\n",
    "\n",
    "fig = px.scatter(tsne_results, x=0, y=1, color=encoded_samples.label.astype(str),labels={'0': 'tsne-2d-one', '1': 'tsne-2d-two'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyp: 0.44057081313189256\n",
    "eucl: 0.423487390100702"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2454a3adb90052121e3433f22c2e288f84a7f03217a2a46086941be12932708b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
