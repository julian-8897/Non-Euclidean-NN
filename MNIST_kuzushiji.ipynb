{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e00c480ae7e3d5e7171f38ea6fedffbe731b8808f4aa360dec46acf6f1daf018"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import feed_forward\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision\r\n",
    "import geoopt\r\n",
    "from time import time\r\n",
    "from torchvision import datasets, transforms\r\n",
    "import helper\r\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "CUDA check"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "device"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Transformation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\r\n",
    "                                #transforms.Normalize((0.1307,), (0.3081,)), \r\n",
    "                              ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training and Test data from MNIST data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "trainset = datasets.KMNIST('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\r\n",
    "valset = datasets.KMNIST('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\r\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True)\r\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=512, shuffle=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz to PATH_TO_STORE_TRAINSET\\KMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting PATH_TO_STORE_TRAINSET\\KMNIST\\raw\\train-images-idx3-ubyte.gz to PATH_TO_STORE_TRAINSET\\KMNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz to PATH_TO_STORE_TRAINSET\\KMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.7%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting PATH_TO_STORE_TRAINSET\\KMNIST\\raw\\train-labels-idx1-ubyte.gz to PATH_TO_STORE_TRAINSET\\KMNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz to PATH_TO_STORE_TRAINSET\\KMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting PATH_TO_STORE_TRAINSET\\KMNIST\\raw\\t10k-images-idx3-ubyte.gz to PATH_TO_STORE_TRAINSET\\KMNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz to PATH_TO_STORE_TRAINSET\\KMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n",
      "C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting PATH_TO_STORE_TRAINSET\\KMNIST\\raw\\t10k-labels-idx1-ubyte.gz to PATH_TO_STORE_TRAINSET\\KMNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz to PATH_TO_STORE_TESTSET\\KMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting PATH_TO_STORE_TESTSET\\KMNIST\\raw\\train-images-idx3-ubyte.gz to PATH_TO_STORE_TESTSET\\KMNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz to PATH_TO_STORE_TESTSET\\KMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.7%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting PATH_TO_STORE_TESTSET\\KMNIST\\raw\\train-labels-idx1-ubyte.gz to PATH_TO_STORE_TESTSET\\KMNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz to PATH_TO_STORE_TESTSET\\KMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting PATH_TO_STORE_TESTSET\\KMNIST\\raw\\t10k-images-idx3-ubyte.gz to PATH_TO_STORE_TESTSET\\KMNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz to PATH_TO_STORE_TESTSET\\KMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting PATH_TO_STORE_TESTSET\\KMNIST\\raw\\t10k-labels-idx1-ubyte.gz to PATH_TO_STORE_TESTSET\\KMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initializing the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = feed_forward.HypFF(784, 512, 256, 10, nn.ReLU())\r\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HypFF(\n",
       "  (act_fn): ReLU()\n",
       "  (fc1): MobLinear(\n",
       "    in_features=784, out_features=512, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       "  (fc2): MobLinear(\n",
       "    in_features=512, out_features=256, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       "  (fc3): MobLinear(\n",
       "    in_features=256, out_features=10, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "HypFF(\n",
      "  (act_fn): ReLU()\n",
      "  (fc1): MobLinear(\n",
      "    in_features=784, out_features=512, bias=True\n",
      "    (ball): PoincareBall manifold\n",
      "  )\n",
      "  (fc2): MobLinear(\n",
      "    in_features=512, out_features=256, bias=True\n",
      "    (ball): PoincareBall manifold\n",
      "  )\n",
      "  (fc3): MobLinear(\n",
      "    in_features=256, out_features=10, bias=True\n",
      "    (ball): PoincareBall manifold\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#learning_rate = 8e-1 \r\n",
    "learning_rate = 2e-1 #learning rate for ReLU activation function\r\n",
    "#learning_rate = 2e-1 #current learning rate for model without activation functions\r\n",
    "momentum = 0.9"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loss Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0231, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0181, -0.0250, -0.0474,  ...,  0.0545,  0.0337, -0.0276],\n",
      "        [ 0.0166, -0.0260, -0.0491,  ...,  0.0478,  0.0311, -0.0256],\n",
      "        [ 0.0219, -0.0251, -0.0460,  ...,  0.0527,  0.0251, -0.0278],\n",
      "        ...,\n",
      "        [ 0.0145, -0.0258, -0.0482,  ...,  0.0547,  0.0307, -0.0275],\n",
      "        [ 0.0184, -0.0262, -0.0478,  ...,  0.0499,  0.0316, -0.0301],\n",
      "        [ 0.0183, -0.0274, -0.0500,  ...,  0.0503,  0.0278, -0.0262]],\n",
      "       device='cuda:0', grad_fn=<SWhereBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "optimizer = geoopt.optim.RiemannianSGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\r\n",
    "time0 = time()\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for e in range(epochs):\r\n",
    "    running_loss = 0\r\n",
    "    for images, labels in trainloader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        # Flatten MNIST images into a 784 long vector\r\n",
    "        images = 0.0357*images.view(images.shape[0], -1)\r\n",
    "    \r\n",
    "        # Training pass\r\n",
    "        optimizer.zero_grad()\r\n",
    "        \r\n",
    "        output = model(images)\r\n",
    "        loss = criterion(output, labels)\r\n",
    "        \r\n",
    "        #backpropagation\r\n",
    "        loss.backward()\r\n",
    "        \r\n",
    "        #Weight optimization\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        running_loss += loss.item()\r\n",
    "    else:\r\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\r\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0 - Training loss: 2.068126487529884\n",
      "Epoch 1 - Training loss: 1.642362650168144\n",
      "Epoch 2 - Training loss: 1.5449403736550928\n",
      "Epoch 3 - Training loss: 1.5019976476491508\n",
      "Epoch 4 - Training loss: 1.4799894720821056\n",
      "Epoch 5 - Training loss: 1.4674443905636416\n",
      "Epoch 6 - Training loss: 1.4574588890803062\n",
      "Epoch 7 - Training loss: 1.4506315760693307\n",
      "Epoch 8 - Training loss: 1.445673509169433\n",
      "Epoch 9 - Training loss: 1.4416773218219563\n",
      "\n",
      "Training Time (in minutes) = 2.5147946159044903\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "images, labels = next(iter(valloader))\r\n",
    "#images, labels = images.to(device), labels.to(device)\r\n",
    "\r\n",
    "img = 0.0357*images[0].view(1, 784)\r\n",
    "img_gpu = img.to(device)\r\n",
    "with torch.no_grad():\r\n",
    "    out = model(img_gpu)\r\n",
    "\r\n",
    "ps = out.cpu()\r\n",
    "print(ps)\r\n",
    "probab = list(ps.numpy()[0])\r\n",
    "print(probab)\r\n",
    "print(\"Predicted Digit =\", probab.index(max(probab)))\r\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0867, -0.1130,  0.9380, -0.1204, -0.1561, -0.1312, -0.0604, -0.1051,\n",
      "         -0.1450, -0.0124]])\n",
      "[-0.08668253, -0.11302746, 0.9379509, -0.12041759, -0.15612562, -0.13124092, -0.060391564, -0.105134346, -0.14498746, -0.012384059]\n",
      "Predicted Digit = 2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "correct_count, all_count = 0, 0\r\n",
    "for images,labels in valloader:\r\n",
    "  images, labels = images.to(device), labels.to(device)\r\n",
    "  for i in range(len(labels)):\r\n",
    "    img = 0.0357*images[i].view(1, 784)\r\n",
    "    with torch.no_grad():\r\n",
    "        out = model(img)\r\n",
    "\r\n",
    "    \r\n",
    "    ps = out.cpu()\r\n",
    "    probab = list(ps.numpy()[0])\r\n",
    "    pred_label = probab.index(max(probab))\r\n",
    "    true_label = labels.cpu().numpy()[i]\r\n",
    "    if(true_label == pred_label):\r\n",
    "      correct_count += 1\r\n",
    "    all_count += 1\r\n",
    "\r\n",
    "print(\"Number Of Images Tested =\", all_count)\r\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.8997\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Current status of experiments:\r\n",
    "1. Using just Hyperboic Linear modules, and with the appropriate self-tuned hyperparameters, and a batch size of 512, the average accuracy was around 90 percent\r\n",
    "2. With the use of activation functions(ReLu, ReLu, then LogSoftMax at the output layer), (by applying the functions in the tangent space, then mapping it back to the hyperbolic space), we see an increase in the model accuracy to about 97-98 percent.\r\n",
    "3. To account for the correct class probabilities , linear layer was used as the output layer instead, together with the crossentropy loss function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}