{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e00c480ae7e3d5e7171f38ea6fedffbe731b8808f4aa360dec46acf6f1daf018"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import feed_forward\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision\r\n",
    "import geoopt\r\n",
    "from time import time\r\n",
    "from torchvision import datasets, transforms\r\n",
    "import helper\r\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "CUDA check"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "device = torch.device('CUDA' if torch.cuda.is_available() else 'CPU')\r\n",
    "print('Using {}'.format(device))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Transformation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\r\n",
    "                                #transforms.Normalize((0.1307,), (0.3081,)), \r\n",
    "                              ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training and Test data from MNIST data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "trainset = datasets.KMNIST('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\r\n",
    "valset = datasets.KMNIST('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\r\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True)\r\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=512, shuffle=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initializing the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = feed_forward.HypFF(784, 512, 256, 10, nn.ReLU())\r\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HypFF(\n",
       "  (act_fn): ReLU()\n",
       "  (fc1): MobLinear(\n",
       "    in_features=784, out_features=512, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       "  (fc2): MobLinear(\n",
       "    in_features=512, out_features=256, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       "  (fc3): MobLinear(\n",
       "    in_features=256, out_features=10, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "HypFF(\n",
      "  (act_fn): ReLU()\n",
      "  (fc1): MobLinear(\n",
      "    in_features=784, out_features=512, bias=True\n",
      "    (ball): PoincareBall manifold\n",
      "  )\n",
      "  (fc2): MobLinear(\n",
      "    in_features=512, out_features=256, bias=True\n",
      "    (ball): PoincareBall manifold\n",
      "  )\n",
      "  (fc3): MobLinear(\n",
      "    in_features=256, out_features=10, bias=True\n",
      "    (ball): PoincareBall manifold\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#learning_rate = 8e-1 \r\n",
    "learning_rate = 2e-1 #learning rate for ReLU activation function\r\n",
    "#learning_rate = 2e-1 #current learning rate for model without activation functions\r\n",
    "momentum = 0.9"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loss Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "optimizer = geoopt.optim.RiemannianSGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\r\n",
    "time0 = time()\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for e in range(epochs):\r\n",
    "    running_loss = 0\r\n",
    "    for images, labels in trainloader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        # Flatten MNIST images into a 784 long vector\r\n",
    "        images = 0.0357*images.view(images.shape[0], -1)\r\n",
    "    \r\n",
    "        # Training pass\r\n",
    "        optimizer.zero_grad()\r\n",
    "        \r\n",
    "        output = model(images)\r\n",
    "        loss = criterion(output, labels)\r\n",
    "        \r\n",
    "        #backpropagation\r\n",
    "        loss.backward()\r\n",
    "        \r\n",
    "        #Weight optimization\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        running_loss += loss.item()\r\n",
    "    else:\r\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\r\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0 - Training loss: 2.3023958367816473\n",
      "Epoch 1 - Training loss: 2.3015386391494235\n",
      "Epoch 2 - Training loss: 2.29311034032854\n",
      "Epoch 3 - Training loss: 2.179897395230956\n",
      "Epoch 4 - Training loss: 2.001126029733884\n",
      "Epoch 5 - Training loss: 1.9057254831669694\n",
      "Epoch 6 - Training loss: 1.865643014342098\n",
      "Epoch 7 - Training loss: 1.8383717971333002\n",
      "Epoch 8 - Training loss: 1.823028756400286\n",
      "Epoch 9 - Training loss: 1.8131826045149464\n",
      "\n",
      "Training Time (in minutes) = 2.6665388544400535\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "images, labels = next(iter(valloader))\r\n",
    "#images, labels = images.to(device), labels.to(device)\r\n",
    "\r\n",
    "img = 0.0357*images[0].view(1, 784)\r\n",
    "img_gpu = img.to(device)\r\n",
    "with torch.no_grad():\r\n",
    "    out = model(img_gpu)\r\n",
    "\r\n",
    "ps = out.cpu()\r\n",
    "print(ps)\r\n",
    "probab = list(ps.numpy()[0])\r\n",
    "print(probab)\r\n",
    "print(\"Predicted Digit =\", probab.index(max(probab)))\r\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.0249, 0.6159, 0.0256, 0.0219, 0.0493, 0.0227, 0.0199, 0.0236, 0.0256,\n",
      "         0.0249]])\n",
      "[0.024880756, 0.6159373, 0.025626674, 0.021919688, 0.0493019, 0.022721129, 0.01993645, 0.023575528, 0.025585553, 0.024855115]\n",
      "Predicted Digit = 1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "correct_count, all_count = 0, 0\r\n",
    "for images,labels in valloader:\r\n",
    "  images, labels = images.to(device), labels.to(device)\r\n",
    "  for i in range(len(labels)):\r\n",
    "    img = 0.0357*images[i].view(1, 784)\r\n",
    "    with torch.no_grad():\r\n",
    "        out = model(img)\r\n",
    "\r\n",
    "    \r\n",
    "    ps = out.cpu()\r\n",
    "    probab = list(ps.numpy()[0])\r\n",
    "    pred_label = probab.index(max(probab))\r\n",
    "    true_label = labels.cpu().numpy()[i]\r\n",
    "    if(true_label == pred_label):\r\n",
    "      correct_count += 1\r\n",
    "    all_count += 1\r\n",
    "\r\n",
    "print(\"Number Of Images Tested =\", all_count)\r\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.8637\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Current status of experiments:\r\n",
    "1. Using just Hyperboic Linear modules, and with the appropriate self-tuned hyperparameters, and a batch size of 512, the average accuracy was around 90 percent\r\n",
    "2. With the use of activation functions(ReLu, ReLu, then LogSoftMax at the output layer), (by applying the functions in the tangent space, then mapping it back to the hyperbolic space), we see an increase in the model accuracy to about 97-98 percent.\r\n",
    "3. To account for the correct class probabilities , linear layer was used as the output layer instead, together with the crossentropy loss function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}