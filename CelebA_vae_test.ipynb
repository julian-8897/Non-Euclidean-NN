{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA experiment for VAE models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import vae_hyp_celeba, vae_eucl_celeba\n",
    "import geoopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from hypmath import poincareball\n",
    "from hypmath import metrics\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "#Disable Debugging APIs\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)\n",
    "\n",
    "#cuDNN Autotuner\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "transform = transforms.Compose([\n",
    "                        transforms.Resize(image_size),\n",
    "                        transforms.CenterCrop(image_size),\n",
    "                        transforms.ToTensor(),\n",
    "                        ])\n",
    "\n",
    "#CelebA data can be downloaded at https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n",
    "trainset = datasets.ImageFolder('data', transform=transform)\n",
    "num_data = list(range(0, 102400))\n",
    "trainset_1 = torch.utils.data.Subset(trainset, num_data)\n",
    "size= len(trainset_1)\n",
    "train_data, val_data = torch.utils.data.random_split(trainset_1, [int(size-size*0.2), int(size*0.2)])\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, \n",
    "                                         num_workers=1, pin_memory=True, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_function = nn.MSELoss(reduction='sum')\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "\n",
    "    \"\"\"\n",
    "    Loss function for VAE:\n",
    "    reconstruction term + regularization term\n",
    "    \"\"\"\n",
    "    MSE = reconstruction_function(recon_x, x)\n",
    "\n",
    "    # https://arxiv.org/abs/1312.6114 (Appendix B)\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return MSE + KLD\n",
    "\n",
    "def train_epoch(vae, dataloader, optimizer):\n",
    "    \"\"\"\n",
    "    Model training function\n",
    "    \"\"\"\n",
    "\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    vae.train()\n",
    "    train_loss = 0.0\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for x, _ in dataloader: \n",
    "        # Move tensor to the proper device\n",
    "        x = x.to(device)\n",
    "        for param in vae.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        recon_x, mu, logvar = vae(x)\n",
    "        # Evaluate loss\n",
    "        loss = loss_function(recon_x, x, mu, logvar)\n",
    "\n",
    "        # Backward pass\n",
    "        #optimizer.zero_grad()   \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        print('\\t partial train loss (single batch): %f' % (loss.item()))\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "    return train_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(vae, dataloader):\n",
    "    \"\"\"\n",
    "    Model validation function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    vae.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        for x, _ in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            x = x.to(device)\n",
    "            recon_x, mu, logvar = vae(x)\n",
    "            # Evaluate loss\n",
    "            loss = loss_function(recon_x, x, mu, logvar)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(encoder,decoder,n):\n",
    "    \"\"\"\n",
    "    Plots the reconstructed images from VAE\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10,4.5))\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2,n,i+1)\n",
    "      img = trainset_1[i][0].unsqueeze(0)\n",
    "      img = img.to(device)\n",
    "      #img = next(iter(trainloader))\n",
    "      encoder.eval()\n",
    "      decoder.eval()\n",
    "      with torch.no_grad():\n",
    "        z, _ , _ = encoder(img)\n",
    "        rec_img  = decoder(z)\n",
    "      plt.imshow(img.cpu().squeeze().permute(1, 2, 0).numpy())\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow((rec_img.cpu().squeeze().permute(1, 2, 0).numpy()))  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vae_eucl_celeba.VariationalAutoencoder(nc=3, ndf=64, ngf=64, latent_dims=500, device=device)\n",
    "#model = vae_hyp_celeba.VariationalAutoencoder(nc=3, ndf=64, ngf=64, latent_dims=100, device=device)\n",
    "model.to(device)\n",
    "print(model)\n",
    "epochs = 5\n",
    "lr = 5e-4\n",
    "#lr = 0.01\n",
    "#optimizer = geoopt.optim.RiemannianAdam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "t_loss = []\n",
    "v_loss = []\n",
    "epoch_values =[]\n",
    "#Training loop\n",
    "for epoch in range(epochs):\n",
    "   train_loss = train_epoch(model, trainloader, optimizer)\n",
    "   val_loss = test_epoch(model, valloader)\n",
    "   t_loss.append(train_loss)\n",
    "   v_loss.append(val_loss)\n",
    "   epoch_values.append(epoch)\n",
    "   print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t validation loss {:.3f}'.format(epoch + 1, epochs, train_loss, val_loss))\n",
    "   plot_ae_outputs(model.encoder, model.decoder,n=4)\n",
    "\n",
    "\n",
    "# save model checkpoint\n",
    "# torch.save({\n",
    "#             'epoch': epochs,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': loss_function,\n",
    "#             }, 'outputs/resnet_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , (ax0) = plt.subplots(1, 1)\n",
    "ax0.set_title('Loss Curves')\n",
    "ax0.plot(epoch_values, t_loss, 'bo-', label='train')\n",
    "ax0.plot(epoch_values, v_loss, 'ro-', label='val')\n",
    "\n",
    "ax0.set_xlabel('Epochs')\n",
    "ax0.set_ylabel('Losses')\n",
    "ax0.legend()\n",
    "\n",
    "fig.suptitle('no. of epochs = {}, lr = {}, batch size = 64'.format(epochs, lr))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the trained model\n",
    "# model_resume = model.to(device) # initilize the model\n",
    "# # initialize optimizer  before loading optimizer state_dict\n",
    "# epochs_new = 5\n",
    "# learning_rate_new = 5e-4\n",
    "# optimizer_new = optim.Adam(model_resume.parameters(), lr=learning_rate_new)\n",
    "\n",
    "\n",
    "# checkpoint = torch.load('outputs/model.pth')\n",
    "\n",
    "# # load model weights state_dict\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# print('Previously trained model weights state_dict loaded...')\n",
    "\n",
    "# # load trained optimizer state_dict\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# print('Previously trained optimizer state_dict loaded...')\n",
    "\n",
    "# epochs = checkpoint['epoch']\n",
    "# # load the criterion\n",
    "# loss_function = checkpoint['loss']\n",
    "# print('Trained model loss function loaded...')\n",
    "# print(f\"Previously trained for {epochs} number of epochs...\")\n",
    "\n",
    "# # train for more epochs\n",
    "# epochs = epochs_new\n",
    "# print(f\"Train for {epochs} more epochs...\")\n",
    "\n",
    "\n",
    "# #New Training loop\n",
    "# for epoch in range(epochs):\n",
    "#    train_loss = train_epoch(model_resume, trainloader, optimizer_new)\n",
    "#    print('\\n EPOCH {}/{} \\t train loss {:.3f}'.format(epoch + 1, epochs, train_loss))\n",
    "#    plot_ae_outputs(model.encoder, model.decoder,n=4)\n",
    "\n",
    "# # save model checkpoint\n",
    "# torch.save({\n",
    "#             'epoch': epochs,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': loss_function,\n",
    "#             }, 'outputs/model.pth')\n",
    "\n",
    "#5,3,3,3,5"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2454a3adb90052121e3433f22c2e288f84a7f03217a2a46086941be12932708b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
