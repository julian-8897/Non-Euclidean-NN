{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e00c480ae7e3d5e7171f38ea6fedffbe731b8808f4aa360dec46acf6f1daf018"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import feed_forward\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision\r\n",
    "import geoopt\r\n",
    "from time import time\r\n",
    "from torchvision import datasets, transforms\r\n",
    "import helper\r\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "CUDA check"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "print('Using {}'.format(device))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, xpu, mkldnn, opengl, opencl, ideep, hip, msnpu, mlc, xla, vulkan, meta, hpu device type at start of device string: CUDA",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15200/1987874605.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CUDA'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'CPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, xpu, mkldnn, opengl, opencl, ideep, hip, msnpu, mlc, xla, vulkan, meta, hpu device type at start of device string: CUDA"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Transformation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\r\n",
    "                                transforms.Normalize((0.1307,), (0.3081,)), \r\n",
    "                              ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training and Test data from MNIST data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\r\n",
    "valset = datasets.MNIST('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\r\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True)\r\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=512, shuffle=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initializing the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = feed_forward.HypFF(784, 512, 256, 10, nn.ReLU())\r\n",
    "ball = geoopt.PoincareBall()\r\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HypFF(\n",
       "  (act_fn): ReLU()\n",
       "  (fc1): MobLinear(\n",
       "    in_features=784, out_features=512, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       "  (fc2): MobLinear(\n",
       "    in_features=512, out_features=256, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       "  (fc3): MobLinear(\n",
       "    in_features=256, out_features=10, bias=True\n",
       "    (ball): PoincareBall manifold\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#learning_rate = 8e-1 \r\n",
    "learning_rate = 4e-1 #learning rate for ReLU activation function\r\n",
    "#learning_rate = 2e-1 #current learning rate for model without activation functions\r\n",
    "momentum = 0.9"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loss Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "criterion = nn.CrossEntropyLoss()\r\n",
    "#criterion = nn.NLLLoss()\r\n",
    "images, labels = next(iter(trainloader))\r\n",
    "images, labels = images.to(device), labels.to(device)\r\n",
    "images = 0.0357*images.view(images.shape[0], -1)\r\n",
    "print(images)\r\n",
    "\r\n",
    "out = model(images) #output\r\n",
    "print(out)\r\n",
    "loss = criterion(out, labels) #calculate the loss"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[-0.3200, -0.3076, -0.3126,  ..., -0.3110, -0.3221, -0.3124],\n",
      "        [-0.3202, -0.3074, -0.3125,  ..., -0.3113, -0.3223, -0.3120],\n",
      "        [-0.3202, -0.3074, -0.3126,  ..., -0.3115, -0.3221, -0.3120],\n",
      "        ...,\n",
      "        [-0.3201, -0.3073, -0.3126,  ..., -0.3111, -0.3220, -0.3125],\n",
      "        [-0.3200, -0.3071, -0.3128,  ..., -0.3111, -0.3225, -0.3121],\n",
      "        [-0.3200, -0.3074, -0.3127,  ..., -0.3112, -0.3224, -0.3122]],\n",
      "       device='cuda:0', grad_fn=<SWhereBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optimizer = geoopt.optim.RiemannianSGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "time0 = time()\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "for e in range(epochs):\r\n",
    "    running_loss = 0\r\n",
    "    for images, labels in trainloader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        # Flatten MNIST images into a 784 long vector\r\n",
    "        #images = 0.0357*images.view(images.shape[0], -1)\r\n",
    "        images = ball.projx(images.view(images.shape[0], -1))\r\n",
    "        \r\n",
    "        # Training pass\r\n",
    "        optimizer.zero_grad()\r\n",
    "        \r\n",
    "        output = model(images)\r\n",
    "        loss = criterion(output, labels)\r\n",
    "        \r\n",
    "        #backpropagation\r\n",
    "        loss.backward()\r\n",
    "        \r\n",
    "        #Weight optimization\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        running_loss += loss.item()\r\n",
    "    else:\r\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\r\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0 - Training loss: 0.30994176081681657\n",
      "Epoch 1 - Training loss: 0.1534982708803678\n",
      "Epoch 2 - Training loss: 0.06521061056498755\n",
      "Epoch 3 - Training loss: 0.05067854955539865\n",
      "Epoch 4 - Training loss: 0.04507155040815725\n",
      "Epoch 5 - Training loss: 0.041322239216859055\n",
      "Epoch 6 - Training loss: 0.038477109902996125\n",
      "Epoch 7 - Training loss: 0.036618647844357005\n",
      "Epoch 8 - Training loss: 0.035227720231070354\n",
      "Epoch 9 - Training loss: 0.034064377642284004\n",
      "\n",
      "Training Time (in minutes) = 2.5823063254356384\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images, labels = next(iter(valloader))\r\n",
    "#images, labels = images.to(device), labels.to(device)\r\n",
    "\r\n",
    "#img = 0.0357*images[0].view(1, 784)\r\n",
    "img = ball.projx(images[0].view(1, 784))\r\n",
    "img_gpu = img.to(device)\r\n",
    "with torch.no_grad():\r\n",
    "    out = model(img_gpu)\r\n",
    "\r\n",
    "ps = out.cpu()\r\n",
    "print(ps)\r\n",
    "probab = list(ps.numpy()[0])\r\n",
    "print(probab)\r\n",
    "print(\"Predicted Digit =\", probab.index(max(probab)))\r\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.7157, 0.7096, 0.7253, 0.7251, 0.7198, 0.7278, 0.7161, 0.7072, 0.7128,\n",
      "         0.9725]])\n",
      "[0.71567965, 0.70961183, 0.7253203, 0.72512954, 0.71979964, 0.72778153, 0.71608937, 0.7071553, 0.7128482, 0.9725337]\n",
      "Predicted Digit = 9\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "correct_count, all_count = 0, 0\r\n",
    "for images,labels in valloader:\r\n",
    "  images, labels = images.to(device), labels.to(device)\r\n",
    "  for i in range(len(labels)):\r\n",
    "    #img = 0.0357*images[i].view(1, 784)\r\n",
    "    img = ball.projx(images[i].view(1, 784))\r\n",
    "    with torch.no_grad():\r\n",
    "        out = model(img)\r\n",
    "\r\n",
    "    \r\n",
    "    ps = out.cpu()\r\n",
    "    probab = list(ps.numpy()[0])\r\n",
    "    pred_label = probab.index(max(probab))\r\n",
    "    true_label = labels.cpu().numpy()[i]\r\n",
    "    if(true_label == pred_label):\r\n",
    "      correct_count += 1\r\n",
    "    all_count += 1\r\n",
    "\r\n",
    "print(\"Number Of Images Tested =\", all_count)\r\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.9743\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Current status of experiments:\r\n",
    "1. Using just Hyperboic Linear modules, and with the appropriate self-tuned hyperparameters, and a batch size of 512, the average accuracy was around 90 percent\r\n",
    "2. With the use of activation functions(ReLu, ReLu, then LogSoftMax at the output layer), (by applying the functions in the tangent space, then mapping it back to the hyperbolic space), we see an increase in the model accuracy to about 97-98 percent.\r\n",
    "3. To account for the correct class probabilities , linear layer was used as the output layer instead, together with the crossentropy loss function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}