{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "2454a3adb90052121e3433f22c2e288f84a7f03217a2a46086941be12932708b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from models import ff_eucl, ff_hyp\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision\r\n",
    "import geoopt\r\n",
    "from time import time\r\n",
    "from torchvision import datasets, transforms\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "import helper\r\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "CUDA check"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "print('Using {}'.format(device))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Transformation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\r\n",
    "                                #transforms.Normalize((0.1307,), (0.3081,)), \r\n",
    "                              ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training and Test data from MNIST data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "train_set = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\r\n",
    "test_set = datasets.MNIST('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\r\n",
    "\r\n",
    "size = len(train_set)\r\n",
    "print(size)\r\n",
    "\r\n",
    "train_data, val_data = torch.utils.data.random_split(train_set, [int(size-size*0.2), int(size*0.2)])\r\n",
    "\r\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=512, shuffle=True)\r\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size=512, shuffle= True)\r\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=512, shuffle= True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initializing the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model = ff_eucl.EuclFF(784, 512, 256, 10, nn.ReLU())\r\n",
    "ball = geoopt.PoincareBall()\r\n",
    "tb = SummaryWriter()\r\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "EuclFF(\n",
       "  (act_fn): ReLU()\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#learning_rate = 8e-1 \r\n",
    "learning_rate = 4e-1 #learning rate for ReLU activation function\r\n",
    "#learning_rate = 2e-1 #current learning rate for model without activation functions\r\n",
    "momentum = 0.9"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loss Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "criterion = nn.CrossEntropyLoss()\r\n",
    "# #criterion = nn.NLLLoss()\r\n",
    "# images, labels = next(iter(trainloader))\r\n",
    "# images, labels = images.to(device), labels.to(device)\r\n",
    "# images = 0.0357*images.view(images.shape[0], -1)\r\n",
    "# print(images)\r\n",
    "\r\n",
    "# out = model(images) #output\r\n",
    "# print(out)\r\n",
    "# loss = criterion(out, labels) #calculate the loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#optimizer = geoopt.optim.RiemannianSGD(model.parameters(), lr=learning_rate, momentum=momentum)\r\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def get_num_correct(preds, labels):\r\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "\r\n",
    "# time0 = time()\r\n",
    "epochs = 10\r\n",
    "for epoch in range(epochs):\r\n",
    "    model.train()\r\n",
    "    train_loss = 0\r\n",
    "    total_correct = 0\r\n",
    "    for images, labels in trainloader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        # Flatten MNIST images into a 784 long vector\r\n",
    "        images = images.view(images.shape[0], -1)\r\n",
    "        #images = ball.projx(images.view(images.shape[0], -1))\r\n",
    "        # Training pass\r\n",
    "        optimizer.zero_grad()\r\n",
    "        output = model(images)\r\n",
    "        loss = criterion(output, labels)  \r\n",
    "        train_loss += loss.item()\r\n",
    "        total_correct += get_num_correct(output, labels)\r\n",
    "        #backpropagation\r\n",
    "        loss.backward()      \r\n",
    "        #Weight optimization\r\n",
    "        optimizer.step()  \r\n",
    "\r\n",
    "    val_loss = 0\r\n",
    "    val_correct = 0\r\n",
    "    model.eval()\r\n",
    "    for  images, labels in valloader:\r\n",
    "        images, labels = images.to(device), labels.to(device)\r\n",
    "        # Flatten MNIST images into a 784 long vector\r\n",
    "        images = images.view(images.shape[0], -1)\r\n",
    "        #images = ball.projx(images.view(images.shape[0], -1))\r\n",
    "        output = model(images)\r\n",
    "        loss = criterion(output, labels)  \r\n",
    "        val_loss += loss.item()\r\n",
    "        val_correct += get_num_correct(output, labels)\r\n",
    "        \r\n",
    "    tb.add_scalar(\"Training Loss\", train_loss, epoch)\r\n",
    "    tb.add_scalar(\"Validation Loss\", val_loss, epoch)\r\n",
    "    tb.add_scalar(\"Training Accuracy\", total_correct/len(train_data), epoch)\r\n",
    "    tb.add_scalar(\"Validation Accuracy\", val_correct/len(val_data), epoch)\r\n",
    "\r\n",
    "    print(\"epoch:\", epoch, \"training loss:\",train_loss, \"validation loss:\", val_loss,\r\n",
    "    \"training accuracy:\", total_correct/len(train_data), \"validation accuracy:\", val_correct/len(val_data))\r\n",
    "    \r\n",
    "tb.close()\r\n",
    "#     else:\r\n",
    "#         print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\r\n",
    "# print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 training loss: 79.55138863623142 validation loss: 5.687320739030838 training accuracy: 0.774375 validation accuracy: 0.9291666666666667\n",
      "epoch: 1 training loss: 15.638271890580654 validation loss: 3.9408125653862953 training accuracy: 0.949875 validation accuracy: 0.95175\n",
      "epoch: 2 training loss: 11.030301179736853 validation loss: 2.8890623822808266 training accuracy: 0.9644166666666667 validation accuracy: 0.9649166666666666\n",
      "epoch: 3 training loss: 8.167212765663862 validation loss: 2.683490216732025 training accuracy: 0.9728125 validation accuracy: 0.967\n",
      "epoch: 4 training loss: 7.152824550867081 validation loss: 2.903259724378586 training accuracy: 0.9757916666666666 validation accuracy: 0.96475\n",
      "epoch: 5 training loss: 5.43487343005836 validation loss: 2.476582784205675 training accuracy: 0.9816041666666667 validation accuracy: 0.97175\n",
      "epoch: 6 training loss: 4.090537885203958 validation loss: 2.6803263798356056 training accuracy: 0.9862291666666667 validation accuracy: 0.9700833333333333\n",
      "epoch: 7 training loss: 3.13361177733168 validation loss: 2.3338334672152996 training accuracy: 0.9890833333333333 validation accuracy: 0.9748333333333333\n",
      "epoch: 8 training loss: 2.754001053981483 validation loss: 2.6683186069130898 training accuracy: 0.9901041666666667 validation accuracy: 0.9728333333333333\n",
      "epoch: 9 training loss: 2.702245268970728 validation loss: 2.933911867439747 training accuracy: 0.9903125 validation accuracy: 0.9711666666666666\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# epochs = 10\r\n",
    "# for epoch in range(epochs):\r\n",
    "#     model.eval()\r\n",
    "#     val_loss = 0\r\n",
    "#     correct = 0\r\n",
    "    \r\n",
    "#     with torch.no_grad():\r\n",
    "#         for images, labels in valloader:\r\n",
    "#             images, labels = images.to(device), labels.to(device)\r\n",
    "#             # Flatten MNIST images into a 784 long vector\r\n",
    "#             images = images.view(images.shape[0], -1)\r\n",
    "#             #images = ball.projx(images.view(images.shape[0], -1))\r\n",
    "#             output = model(images)\r\n",
    "#             loss = criterion(output, labels)  \r\n",
    "#             val_loss += loss.item()\r\n",
    "#             correct += get_num_correct(output, labels)\r\n",
    "\r\n",
    "#         tb.add_scalar(\"Validation Loss\", val_loss, epoch)\r\n",
    "#         tb.add_scalar(\"Validation Accuracy\", correct/len(val_data), epoch)\r\n",
    "#         print(\"epoch:\", epoch, \"total correct:\", correct, \"validation loss:\",val_loss)\r\n",
    "#         print(\"Validation Accuracy\", correct/len(val_data))\r\n",
    "# tb.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# images, labels = next(iter(testloader))\r\n",
    "# #images, labels = images.to(device), labels.to(device)\r\n",
    "\r\n",
    "# img = images[0].view(1, 784)\r\n",
    "# #img = ball.projx(images[0].view(1, 784))\r\n",
    "# #img_gpu = img.to(device)\r\n",
    "# with torch.no_grad():\r\n",
    "#     out = model(img)\r\n",
    "\r\n",
    "# ps = out.cpu()\r\n",
    "# print(ps)\r\n",
    "# probab = list(ps.numpy()[0])\r\n",
    "# print(probab)\r\n",
    "# print(\"Predicted Digit =\", probab.index(max(probab)))\r\n",
    "# helper.view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Model Prediction and Model Accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "correct_count, all_count = 0, 0\r\n",
    "for images,labels in testloader:\r\n",
    "  images, labels = images.to(device), labels.to(device)\r\n",
    "  for i in range(len(labels)):\r\n",
    "    img = images[i].view(1, 784)\r\n",
    "    #img = ball.projx(images[i].view(1, 784))\r\n",
    "    with torch.no_grad():\r\n",
    "        out = model(img)\r\n",
    "\r\n",
    "    ps = out.cpu()\r\n",
    "    probab = list(ps.numpy()[0])\r\n",
    "    pred_label = probab.index(max(probab))\r\n",
    "    true_label = labels.cpu().numpy()[i]\r\n",
    "    if(true_label == pred_label):\r\n",
    "      correct_count += 1\r\n",
    "    all_count += 1\r\n",
    "    \r\n",
    "print(\"Number Of Images Tested =\", all_count)\r\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.9708\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Current status of experiments:\r\n",
    "1. Using just Hyperboic Linear modules, and with the appropriate self-tuned hyperparameters, and a batch size of 512, the average accuracy was around 90 percent\r\n",
    "2. With the use of activation functions(ReLu, ReLu, then LogSoftMax at the output layer), (by applying the functions in the tangent space, then mapping it back to the hyperbolic space), we see an increase in the model accuracy to about 97-98 percent.\r\n",
    "3. To account for the correct class probabilities , linear layer was used as the output layer instead, together with the crossentropy loss function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}